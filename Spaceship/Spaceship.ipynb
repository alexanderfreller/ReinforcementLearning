{"cells":[{"cell_type":"code","metadata":{},"outputs":[],"source":["import tensorflow as tf\n","import tensorflow.keras.layers as layers\n","import gym\n","import numpy as np\n","import random\n","import math"]},{"cell_type":"code","metadata":{},"outputs":[],"source":["def buildModel():\n","    inputs = tf.keras.Input(shape=(8))\n","    x = layers.Dense(32,activation='relu')(inputs)\n","    x = layers.Dense(64,activation='relu')(x)\n","    x = layers.Dense(32,activation='relu')(x)\n","    x = layers.Dense(4)(x)\n","\n","    return tf.keras.Model(inputs = inputs, outputs = x) "]},{"cell_type":"code","metadata":{},"outputs":[],"source":["class Memory():\n","    def __init__(self, size):\n","        self.size = size\n","        self.memory = []\n","\n","    def sample(self,n):\n","        n = self.size if n > self.size else n\n","        return random.choices(self.memory,k=n)\n","    \n","    def add(self,sample):\n","        self.memory.append(sample)\n","        if len(self.memory) > self.size:\n","            self.memory.pop(0)\n","    \n","    def __len__(self):\n","        return len(self.memory)\n","        "]},{"cell_type":"code","metadata":{},"outputs":[],"source":["env = gym.make('LunarLander-v2')\n","\n","online = buildModel()\n","target = buildModel()\n","\n","optimizer=tf.keras.optimizers.Adam()\n","loss = tf.keras.losses.MeanSquaredError()\n","\n","memory = Memory(200000)"]},{"cell_type":"code","metadata":{},"outputs":[],"source":["MAX_EPSILON = 1\n","MIN_EPSILON = 0.01\n","LAMBDA = 0.00005\n","GAMMA = 0.95\n","BS = 128\n","TAU = 0.08"]},{"cell_type":"code","metadata":{},"outputs":[],"source":["def train(memory,online,target):\n","    batch = memory.sample(BS)\n","    states = np.array([val[0] for val in batch])\n","    actions = np.array([val[1] for val in batch])\n","    rewards = np.array([val[2] for val in batch])\n","    next_states = np.array([val[3] for val in batch])\n","    dones = np.array([val[4] for val in batch])\n","\n","    with tf.GradientTape() as t:\n","\n","        q = online(states)\n","        next_q_online = online(next_states)\n","        next_q_target = target(next_states)\n","\n","        next_actions = tf.argmax(next_q_online,axis=1)\n","\n","        action_q = tf.gather(q,actions[:,None],batch_dims=1)\n","\n","        target_q = rewards\n","        mask = np.logical_not(dones).astype('float')\n","        discounted_q = tf.gather(next_q_target,next_actions[:,None],batch_dims=1) * GAMMA\n","        masked_q = tf.math.multiply(tf.squeeze(discounted_q),mask)\n","        target_q += masked_q\n","\n","        loss_value = loss(target_q,action_q)\n","\n","        grads = t.gradient(loss_value, online.trainable_variables)\n","        optimizer.apply_gradients(zip(grads,online.trainable_variables))\n","\n","        for o,t in zip(online.trainable_variables,target.trainable_variables):\n","            t.assign(t * (1- TAU) + o * TAU)\n","        \n","        return loss_value"]},{"cell_type":"code","metadata":{},"outputs":[],"source":["e = MAX_EPSILON\n","step = 0"]},{"cell_type":"code","metadata":{},"outputs":[],"source":["render = True"]},{"cell_type":"code","metadata":{},"outputs":[],"source":["for episode in range(1000):\n","\n","    done = False\n","    state = np.array(env.reset())\n","    totalReward = 0\n","    loss_value = 0\n","\n","    while not done:\n","        if render: env.render()\n"," \n","        q = online(state[None,:])\n","        if np.random.rand() < e:\n","            action = np.random.randint(low=0, high=env.action_space.n)\n","        else:\n","            action = tf.argmax(q,axis=1).numpy()[0] \n","\n","        next_state,reward,done,info = env.step(action)\n","\n","        memory.add((state,action,reward,next_state,done))\n","\n","        if(len(memory) > BS):\n","            train(memory,online,target)\n","\n","        state = next_state\n","        \n","        step += 1\n","        e = MIN_EPSILON + (MAX_EPSILON - MIN_EPSILON) * math.exp(-LAMBDA * step)\n","        totalReward += reward\n","\n","    print(episode,totalReward)\n","\n","env.close()"]},{"cell_type":"code","metadata":{},"outputs":[],"source":[]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3},"version":"3.7.4"},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}